{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro-title",
      "metadata": {},
      "source": [
        "# ðŸ“˜ Agentic Architectures 3: ReAct (Reason + Act)\n",
        "\n",
        "Welcome to the third notebook in our series. We will now explore **ReAct**, a pivotal architecture that bridges the gap between simple tool use and complex, multi-step problem-solving. ReAct stands for **Reason + Act**, and its core innovation is the way it enables an agent to dynamically reason about a problem, act on its reasoning, observe the outcome, and then reason again.\n",
        "\n",
        "This pattern transforms an agent from a static tool-caller into an adaptive problem-solver. To highlight its power, we will first build a **basic, single-shot tool-using agent** and show its limitations on a complex task. Then, we will build a full ReAct agent and demonstrate how its iterative `think -> act -> observe` loop allows it to succeed where the basic agent fails."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intro-definition",
      "metadata": {},
      "source": [
        "### Definition\n",
        "The **ReAct** architecture is a design pattern where an agent interleaves reasoning steps with actions. Instead of planning all its steps upfront, the agent generates a thought about its immediate next step, takes an action (like calling a tool), observes the result, and then uses that new information to generate its next thought and action. This creates a dynamic and adaptive loop.\n",
        "\n",
        "### High-level Workflow\n",
        "\n",
        "1.  **Receive Goal:** The agent is given a complex task.\n",
        "2.  **Think (Reason):** The agent generates an internal thought, such as: *\"To answer this, I first need to find piece of information X.\"*\n",
        "3.  **Act:** Based on its thought, the agent executes an action, typically calling a tool (e.g., `search_api('X')`).\n",
        "4.  **Observe:** The agent receives the result from the tool.\n",
        "5.  **Repeat:** The agent incorporates the observation into its context and returns to step 2, generating a new thought (e.g., *\"Okay, now that I have X, I need to use it to find Y.\"*). This loop continues until the overall goal is satisfied.\n",
        "\n",
        "### When to Use / Applications\n",
        "*   **Multi-hop Question Answering:** When answering a question requires finding several pieces of information in sequence (e.g., \"Who is the CEO of the company that makes the iPhone?\").\n",
        "*   **Web Navigation & Research:** An agent can search for a starting point, read the results, and then decide on a new search query based on what it learned.\n",
        "*   **Interactive Workflows:** Any task where the environment is dynamic and the full path to a solution cannot be known in advance.\n",
        "\n",
        "### Strengths & Weaknesses\n",
        "*   **Strengths:**\n",
        "    *   **Adaptive & Dynamic:** Can adjust its plan on the fly based on new information.\n",
        "    *   **Handles Complexity:** Excels at problems that require chaining multiple dependent steps.\n",
        "*   **Weaknesses:**\n",
        "    *   **Higher Latency & Cost:** Involves multiple sequential LLM calls, making it slower and more expensive than single-shot approaches.\n",
        "    *   **Risk of Loops:** A poorly guided agent can get stuck in repetitive, unproductive loops of thought and action."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "phase0-title",
      "metadata": {},
      "source": [
        "## Phase 0: Foundation & Setup\n",
        "\n",
        "We'll begin with our standard setup process: installing libraries and configuring API keys for Nebius, LangSmith, and our Tavily web search tool."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup-what",
      "metadata": {},
      "source": [
        "### Step 0.1: Installing Core Libraries\n",
        "\n",
        "**What we are going to do:**\n",
        "We will install our standard suite of libraries for this project series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "install-libs",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -q -U langchain-nebius langchain langgraph rich python-dotenv tavily-python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "imports-what",
      "metadata": {},
      "source": [
        "### Step 0.2: Importing Libraries and Setting Up Keys\n",
        "\n",
        "**What we are going to do:**\n",
        "We will import the necessary modules and load our API keys from a `.env` file.\n",
        "\n",
        "**Action Required:** Create a `.env` file in this directory with your keys:\n",
        "```\n",
        "NEBIUS_API_KEY=\"your_nebius_api_key_here\"\n",
        "LANGCHAIN_API_KEY=\"your_langsmith_api_key_here\"\n",
        "TAVILY_API_KEY=\"your_tavily_api_key_here\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "import-and-keys",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Annotated\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# LangChain components\n",
        "from langchain_nebius import ChatNebius\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import BaseMessage\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# LangGraph components\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.graph.message import AnyMessage, add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "# For pretty printing\n",
        "from rich.console import Console\n",
        "from rich.markdown import Markdown\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# --- API Key and Tracing Setup ---\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Agentic Architecture - ReAct (Nebius)\"\n",
        "\n",
        "# Check that the keys are set\n",
        "for key in [\"NEBIUS_API_KEY\", \"LANGCHAIN_API_KEY\", \"TAVILY_API_KEY\"]:\n",
        "    if not os.environ.get(key):\n",
        "        print(f\"{key} not found. Please create a .env file and set it.\")\n",
        "\n",
        "print(\"Environment variables loaded and tracing is set up.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "phase1-title",
      "metadata": {},
      "source": [
        "## Phase 1: The Basic Approach - A Single-Shot Tool User\n",
        "\n",
        "To understand why ReAct is so powerful, we must first see what happens without it. We will build a \"basic\" agent that can use tools, but only once. It will analyze a user's query, make a single tool call, and then try to formulate a final answer based on that one piece of information."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "basic-what",
      "metadata": {},
      "source": [
        "### Step 1.1: Building the Basic Agent\n",
        "\n",
        "**What we are going to do:**\n",
        "We will define the same tool and LLM as before, but we will wire them into a simple, linear graph. The agent gets one chance to call a tool, and then the workflow ends. There is no loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "07e92784",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM initialized: databricks-claude-opus-4-6 (via databricks)\n"
          ]
        }
      ],
      "source": [
        "from helpers import get_llm\n",
        "\n",
        "llm = get_llm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "basic-build",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "console = Console()\n",
        "\n",
        "# Define the state for our graphs\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]\n",
        "\n",
        "# Define the tool and LLM\n",
        "search_tool = TavilySearchResults(max_results=2, name=\"web_search\")\n",
        "# llm = ChatNebius(model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\", temperature=0)\n",
        "# llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
        "llm_with_tools = llm.bind_tools([search_tool])\n",
        "\n",
        "# Define the agent node for the basic agent\n",
        "def basic_agent_node(state: AgentState):\n",
        "    console.print(\"--- BASIC AGENT: Thinking... ---\")\n",
        "    # Note: We provide a system prompt to encourage it to answer directly after one tool call\n",
        "    system_prompt = \"\"\"You are a helpful assistant. You have access to a web search tool.\n",
        "                       Answer the user's question based on the tool's results. \n",
        "                       You must provide a final answer after one tool call.\"\"\"\n",
        "                       \n",
        "    messages = [(\"system\", system_prompt)] + state[\"messages\"]\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# Define the basic, linear graph\n",
        "basic_graph_builder = StateGraph(AgentState)\n",
        "basic_graph_builder.add_node(\"agent\", basic_agent_node)\n",
        "basic_graph_builder.add_node(\"tools\", ToolNode([search_tool]))\n",
        "\n",
        "basic_graph_builder.set_entry_point(\"agent\")\n",
        "# After the agent, it can only go to tools, and after tools, it MUST end.\n",
        "basic_graph_builder.add_conditional_edges(\"agent\", tools_condition, {\"tools\": \"tools\", \"__end__\": \"__end__\"})\n",
        "basic_graph_builder.add_edge(\"tools\", END)\n",
        "\n",
        "basic_tool_agent_app = basic_graph_builder.compile()\n",
        "\n",
        "print(\"Basic single-shot tool-using agent compiled successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c6765e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "Image(basic_tool_agent_app.get_graph().draw_mermaid_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "basic-test-what",
      "metadata": {},
      "source": [
        "### Step 1.2: Testing the Basic Agent on a Multi-Step Problem\n",
        "\n",
        "**What we are going to do:**\n",
        "Now we'll give the basic agent a problem that requires multiple, dependent steps to solve. This will expose its fundamental weakness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "basic-test-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "multi_step_query = \"Who is the current CEO of the company that created the sci-fi movie 'Dune', and what was the budget for that company's most recent film?\"\n",
        "\n",
        "console.print(f\"[bold yellow]Testing BASIC agent on a multi-step query:[/bold yellow] '{multi_step_query}'\\n\")\n",
        "\n",
        "basic_agent_output = basic_tool_agent_app.invoke({\"messages\": [(\"user\", multi_step_query)]})\n",
        "\n",
        "console.print(\"\\n--- [bold red]Final Output from Basic Agent[/bold red] ---\")\n",
        "console.print(Markdown(basic_agent_output['messages'][-1].content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "basic-discuss",
      "metadata": {},
      "source": [
        "**Discussion of the Output:**\n",
        "As expected, the basic agent failed. Its single tool call was likely a search for the entire long query. The search results for such a complex, conjunctive query are often messy and don't contain all the necessary pieces of information in one place. \n",
        "\n",
        "The agent's final answer is probably incomplete, incorrect, or a statement that it cannot find the information. It was unable to break the problem down:\n",
        "1.  Find the company that made 'Dune' (Legendary Entertainment).\n",
        "2.  Find the CEO of that company (Joshua Grode).\n",
        "3.  Find that company's most recent film and its budget.\n",
        "\n",
        "This failure perfectly illustrates the need for a more dynamic approach. The agent needs a way to **react** to the information it finds in one step to inform the next."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "phase2-title",
      "metadata": {},
      "source": [
        "## Phase 2: The Advanced Approach - Implementing ReAct\n",
        "\n",
        "Now, we'll build the true ReAct agent. The core difference is the graph's structure: we will introduce a loop that allows the agent to repeatedly think, act, and observe."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "react-build-what",
      "metadata": {},
      "source": [
        "### Step 2.1: Building the ReAct Agent Graph\n",
        "\n",
        "**What we are going to do:**\n",
        "We will define the nodes and the crucial router function that creates the `think -> act` loop. The key architectural change is the edge that routes the output from the `tool_node` *back* to the `agent_node`, allowing the agent to see the results and decide on its next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "react-build-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "def react_agent_node(state: AgentState):\n",
        "    console.print(\"--- REACT AGENT: Thinking... ---\")\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# The ToolNode is the same as before\n",
        "react_tool_node = ToolNode([search_tool])\n",
        "\n",
        "# The router is also the same logic\n",
        "def react_router(state: AgentState):\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if last_message.tool_calls:\n",
        "        console.print(\"--- ROUTER: Decision is to call a tool. ---\")\n",
        "        return \"tools\"\n",
        "    console.print(\"--- ROUTER: Decision is to finish. ---\")\n",
        "    return \"__end__\"\n",
        "\n",
        "# Now we define the graph with the crucial loop\n",
        "react_graph_builder = StateGraph(AgentState)\n",
        "react_graph_builder.add_node(\"agent\", react_agent_node)\n",
        "react_graph_builder.add_node(\"tools\", react_tool_node)\n",
        "\n",
        "react_graph_builder.set_entry_point(\"agent\")\n",
        "react_graph_builder.add_conditional_edges(\"agent\", react_router, {\"tools\": \"tools\", \"__end__\": \"__end__\"})\n",
        "\n",
        "# This is the key difference: the edge goes from tools BACK to the agent\n",
        "react_graph_builder.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "react_agent_app = react_graph_builder.compile()\n",
        "print(\"ReAct agent compiled successfully with a reasoning loop.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "phase3-title",
      "metadata": {},
      "source": [
        "## Phase 3: Head-to-Head Comparison\n",
        "\n",
        "Now we will run the same complex query with our new ReAct agent and observe the difference in its process and final output."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "react-test-what",
      "metadata": {},
      "source": [
        "### Step 3.1: Testing the ReAct Agent on the Multi-Step Problem\n",
        "\n",
        "**What we are going to do:**\n",
        "We will invoke the ReAct agent with the same multi-step query and stream the output to see its iterative reasoning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "react-test-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "console.print(f\"[bold green]Testing ReAct agent on the same multi-step query:[/bold green] '{multi_step_query}'\\n\")\n",
        "\n",
        "final_react_output = None\n",
        "for chunk in react_agent_app.stream({\"messages\": [(\"user\", multi_step_query)]}, stream_mode=\"values\"):\n",
        "    final_react_output = chunk\n",
        "    console.print(f\"--- [bold purple]Current State[/bold purple] ---\")\n",
        "    chunk['messages'][-1].pretty_print()\n",
        "    console.print(\"\\n\")\n",
        "\n",
        "console.print(\"\\n--- [bold green]Final Output from ReAct Agent[/bold green] ---\")\n",
        "console.print(Markdown(final_react_output['messages'][-1].content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "react-discuss",
      "metadata": {},
      "source": [
        "**Discussion of the Output:**\n",
        "Success! The execution trace shows a completely different and far more intelligent process. You can see the agent's step-by-step reasoning:\n",
        "1.  **Thought 1:** It first reasons that it needs to identify the production company for 'Dune'.\n",
        "2.  **Action 1:** It calls the `web_search` tool with a query like \"production company for Dune movie\".\n",
        "3.  **Observation 1:** It receives the result: \"Legendary Entertainment\".\n",
        "4.  **Thought 2:** Now, incorporating the new information, it reasons that it needs the CEO of Legendary Entertainment.\n",
        "5.  **Action 2:** It calls `web_search` again with a query like \"CEO of Legendary Entertainment\".\n",
        "6.  ...and so on, until it has gathered all the necessary pieces.\n",
        "7.  **Synthesis:** Finally, it assembles all the collected facts into a complete and accurate answer.\n",
        "\n",
        "This clearly demonstrates the superiority of the ReAct pattern for any task that isn't a simple, single-step lookup."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eval-what",
      "metadata": {},
      "source": [
        "## Phase 4: Quantitative Evaluation\n",
        "\n",
        "To formalize the comparison, we'll use an LLM-as-a-Judge to score the final outputs from both the basic and the ReAct agents on their ability to solve the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eval-judge-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TaskEvaluation(BaseModel):\n",
        "    \"\"\"Schema for evaluating an agent's ability to complete a task.\"\"\"\n",
        "    task_completion_score: int = Field(description=\"Score 1-10 on whether the agent successfully completed all parts of the user's request.\")\n",
        "    reasoning_quality_score: int = Field(description=\"Score 1-10 on the logical flow and reasoning process demonstrated by the agent.\")\n",
        "    justification: str = Field(description=\"A brief justification for the scores.\")\n",
        "\n",
        "judge_llm = llm.with_structured_output(TaskEvaluation)\n",
        "\n",
        "def evaluate_agent_output(query: str, agent_output: dict):\n",
        "    trace = \"\\n\".join([f\"{m.type}: {m.content}\" for m in agent_output['messages']])\n",
        "    prompt = f\"\"\"You are an expert judge of AI agents. Evaluate the following agent's performance on the given task on a scale of 1-10. A score of 10 means the task was completed perfectly. A score of 1 means complete failure.\n",
        "    \n",
        "    **User's Task:**\n",
        "    {query}\n",
        "    \n",
        "    **Full Agent Conversation Trace:**\n",
        "    ```\n",
        "    {trace}\n",
        "    ```\n",
        "    \"\"\"\n",
        "    return judge_llm.invoke(prompt)\n",
        "\n",
        "console.print(\"--- Evaluating Basic Agent's Output ---\")\n",
        "basic_agent_evaluation = evaluate_agent_output(multi_step_query, basic_agent_output)\n",
        "console.print(basic_agent_evaluation.model_dump())\n",
        "\n",
        "console.print(\"\\n--- Evaluating ReAct Agent's Output ---\")\n",
        "react_agent_evaluation = evaluate_agent_output(multi_step_query, final_react_output)\n",
        "console.print(react_agent_evaluation.model_dump())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eval-discuss",
      "metadata": {},
      "source": [
        "**Discussion of the Output:**\n",
        "The quantitative scores from the LLM-as-a-Judge make the difference crystal clear. \n",
        "- The **Basic Agent** received a very low `task_completion_score` because it failed to gather all the required information. Its `reasoning_quality_score` is also low because its process was flawed and incomplete.\n",
        "- The **ReAct Agent**, in contrast, received near-perfect scores. The judge recognized that its iterative process allowed it to successfully complete all parts of the complex task.\n",
        "\n",
        "This head-to-head comparison and evaluation provides definitive proof of the ReAct architecture's value. It is the key that unlocks an agent's ability to tackle complex, multi-hop problems that require dynamic adaptation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we have not only implemented the **ReAct** architecture but also demonstrated its clear superiority over a more basic, single-shot approach. By building a workflow that allows an agent to loop through a cycle of reasoning and acting, we have enabled it to solve complex, multi-step problems that would otherwise be intractable.\n",
        "\n",
        "The ability to observe the outcome of an action and use that information to inform the next step is a fundamental component of intelligent behavior. The ReAct pattern provides a simple yet profoundly effective way to build this capability into our AI agents, making them more powerful, adaptive, and useful for real-world tasks."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
